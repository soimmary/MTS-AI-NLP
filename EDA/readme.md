Здесь то, что я смог выковырять из данных. В основном там некрасивые графики, по которым вряд ли что-то можно хорошее сказать, но я вроде сказал. В основном там я просто мотивирую свой выбор пайплайна и выделяю самые базовые фичи, вроде бы всё это полезно, так что резюмирую свои находки:

1. Пайплайн:
 1) `lemmatize=True`, для английского полезно, потому что падежей и так толком нет, так получается быстрее, меньше словарь, более устойчивые данные
 2) `remove_contrations=True`, на самом деле не считал, влияют они на что-то или нет, скорее всего нет
 3) `remove_numbers=True`, пока щас писал, подумал, что наличие чисел может быть прямо связано с лейблами типа обналичивания, мб стоит проверить
 4) `fix_spelling=True`, просто для единообразия, мб стоит убрать, потому что довольно ресурсозатратно, хотя это и вопрос пары секунд
 5) `remove_punctuation=True`, не вижу, как они могут нам помочь, хотя корреляция с их числом есть

2. Новые фичи:
 1) `punct_count`, есть лейблы, в которых люди очень часто любят писать !!!! или ????, обычно, когда проблемы с картой, пруфы в тетрадке
 2) `sw_count`, по-моему это юзлесс признак, потому что он коррелирует с длиной предложения, если честно, просто забыл убрать
 3) `cased_count`, аналогично (1), в некоторых ситуациях люди много пишут КАПСОМ, причём лейблы другие, не как в (1)
 4) `sent_len`, больше для берта нужно - в основном предложения до 52 токенов, но feature_importance показывает, что влияние есть, хоть и не очень большое
 5) `char_count`, та же причина - как-то влияет на скор, поэтому оставил
 6) `text_density`, средняя длина токенов на предложение, топ-2 фича по важности, видимо некоторые интенты просто обязаны содержать слова подлиннее
 7) `pos_counts`, ценность фичи не доказана, скорее просто характеристика датасета - глаголов довольно много
 8) `polarity`, определённые интенты чаще всплывают в негативных контекстах. Я размечал очень простеньким классификатором, мб имеет смысл взять что-то по сложнее, потому что это топ-3 фича

3. Бейзлайн:
 - неоптимизированный `CatBoostClassifier` на сырых данных выдаёт F1 $\approx$ 0.815, на предобработанных $\approx$ 0.86

Не считая добавления ещё чего-то, можно из них взять какое-нибудь среднее, минимум, максимум, поможет или нет, сказать сложно
Катбуст даже без оптимизации хуже берта - https://huggingface.co/philschmid/BERT-Banking77 всего на 0.06, при этом на инференсе считает моментально, к тому же может быть полезен, если получится его состакать
